{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "dcgan_commented.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6009ffc636d4776a04dfaa93ab8accf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ad5e041593e432d896a6aaa9905c86d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee124b290ca744c68e78a6718a0f4b9d",
              "IPY_MODEL_435851aa0c1e4bb680c722b33f2ebf4e"
            ]
          }
        },
        "5ad5e041593e432d896a6aaa9905c86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee124b290ca744c68e78a6718a0f4b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c02e186b29f480ebd3efd80c3a98549",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fcb5c78b845445fa23c5beb3c0a0ee6"
          }
        },
        "435851aa0c1e4bb680c722b33f2ebf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6de73e04b6141e5a9b360743a4be784",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 34018731.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6647bb7c1cb74261b614131e6116d8d3"
          }
        },
        "8c02e186b29f480ebd3efd80c3a98549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fcb5c78b845445fa23c5beb3c0a0ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6de73e04b6141e5a9b360743a4be784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6647bb7c1cb74261b614131e6116d8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rameshveer/ML_Algorithms/blob/master/Deep_Convolutional_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHhxoX-IaXWp"
      },
      "source": [
        "# Deep Convolutional GANs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pefBj0MCaXWr"
      },
      "source": [
        "# import the libraries\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOcwsSWn7OBo",
        "outputId": "a3fdcc16-bc23-4d0c-bf65-1fa8790daa92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jnocH8QaXWx"
      },
      "source": [
        "# Setting some hyperparameters\n",
        "# We set the size of the batch\n",
        "\n",
        "batchSize = 64\n",
        "\n",
        "# We set the size of the generated images (64x64)\n",
        "\n",
        "imageSize = 64"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcq3R9peaXW1",
        "outputId": "b575541b-08de-4456-e8d0-c3faa784faeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating the transformations\n",
        "# We create a list of transformations (scaling, tensor conversion, normalization) to apply to the input images\n",
        "\n",
        "transform = transforms.Compose([transforms.Scale(imageSize), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:280: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxtWfBrFaXW7",
        "outputId": "786e1be3-6ced-4773-9938-1fbe5ab6e897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "b6009ffc636d4776a04dfaa93ab8accf",
            "5ad5e041593e432d896a6aaa9905c86d",
            "ee124b290ca744c68e78a6718a0f4b9d",
            "435851aa0c1e4bb680c722b33f2ebf4e",
            "8c02e186b29f480ebd3efd80c3a98549",
            "1fcb5c78b845445fa23c5beb3c0a0ee6",
            "d6de73e04b6141e5a9b360743a4be784",
            "6647bb7c1cb74261b614131e6116d8d3"
          ]
        }
      },
      "source": [
        "# Loading the dataset\n",
        "# We download the training set in the ./data folder and we apply the previous transformations on each image\n",
        "\n",
        "dataset = dset.CIFAR10(root = './data', download = True, transform = transform)\n",
        "\n",
        "# We use dataLoader to get the images of the training set batch by batch\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6009ffc636d4776a04dfaa93ab8accf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvsBx2EaRtE2"
      },
      "source": [
        "#checking the availability of cuda devices\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU0P2QUEWzk_"
      },
      "source": [
        "ngpu = 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVKJGTTpaXXB"
      },
      "source": [
        "# Defining the weights_init function that takes as input a neural network m and that will initialize all its weights\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk2OZ0XjaXXF"
      },
      "source": [
        "# Defining the generator\n",
        "# We introduce a class to define the generator\n",
        "# We introduce the __init__() function that will define the architecture of the generator\n",
        "# We inherit from the nn.Module tools\n",
        "# We create a meta module of a neural network that will contain a sequence of modules \n",
        "#(convolutions, full connections, etc.)\n",
        "# We start with the first inversed convolution\n",
        "# We normalize all the features along the dimension of the batch\n",
        "# We apply a ReLU rectification to break the linearity\n",
        "# We add the second later of inversed convolution\n",
        "# We normalize again\n",
        "# We apply the ReLU activation function\n",
        "# We add the third layer of inversed convolution\n",
        "# We normalize again\n",
        "# We apply the ReLU activation function\n",
        "# We add the fourth layer of inversed convolution\n",
        "# We normalize again\n",
        "# We apply the ReLU activation function\n",
        "# We add the fifth layer of inversed convolution\n",
        "# We apply a Tanh rectification to break the linearity and stay between -1 and +1\n",
        "\n",
        "class G(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(G, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "# We define the forward function that takes as argument an input that will be fed to the neural network, \n",
        "# and that will return the output containing the generated images\n",
        "# We forward propagate the signal through the whole neural network of the generator defined by self.main\n",
        "# We return the output containing the generated images\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlUrGWRJaXXI",
        "outputId": "f44ea0ea-3968-4bef-c47f-01c2c87a8047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating the generator\n",
        "\n",
        "# We create the generator object\n",
        "# We initialize all the weights of its neural network\n",
        "\n",
        "netG = G().to(device)\n",
        "netG.apply(weights_init)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "G(\n",
              "  (main): Sequential(\n",
              "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (13): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMk3w4bLaXXN"
      },
      "source": [
        "# Defining the discriminator\n",
        "# We introduce a class to define the discriminator\n",
        "# We introduce the __init__() function that will define the architecture of the discriminator\n",
        "# We inherit from the nn.Module tools\n",
        "# We create a meta module of a neural network \n",
        "# that will contain a sequence of modules (convolutions, full connections, etc.)\n",
        "# We start with a convolution\n",
        "# We apply a LeakyReLU\n",
        "# We add another convolution\n",
        "# We normalize all the features along the dimension of the batch\n",
        "# We apply another LeakyReLU\n",
        "# We add another convolution\n",
        "# We normalize again\n",
        "# We apply another LeakyReLU\n",
        "# We add another convolution\n",
        "# We normalize again\n",
        "\n",
        "class D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(D, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace = True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output.view(-1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nAr2QQOaXXQ",
        "outputId": "b32f14ad-e5e7-45ee-a289-f3c03627aa56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating the discriminator\n",
        "\n",
        "netD = D().to(device)\n",
        "netD.apply(weights_init)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "D(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (12): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEaSD6f0aXXT"
      },
      "source": [
        "# Training the DCGANs\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FDeODC_cgBy"
      },
      "source": [
        "import os\n",
        "os.mkdir('results')\n",
        "#os.mkdir('weights')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPVDhsrmpnsG"
      },
      "source": [
        "fixed_noise = torch.randn(128, 100, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "niter = 5\n",
        "g_loss = []\n",
        "d_loss = []"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "810YYGMNaXXW",
        "outputId": "9eed3328-bcc3-4ada-b8aa-eba26161a7b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(niter):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        # train with real\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "\n",
        "        output = netD(real_cpu)\n",
        "        errD_real = criterion(output, label.float())\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output, label.float())\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, label.float())\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        \n",
        "        #save the output\n",
        "        if i % 100 == 0:\n",
        "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (epoch, niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            vutils.save_image(real_cpu,'results/real_samples.png',normalize=True)\n",
        "            fake = netG(fixed_noise)\n",
        "            vutils.save_image(fake.detach(),'results/fake_samples_epoch_%03d.png' % (epoch),normalize=True)\n",
        "    \n",
        "    # Check pointing for every epoch\n",
        "    torch.save(netG.state_dict(), 'weights/netG_epoch_%d.pth' % (epoch))\n",
        "    torch.save(netD.state_dict(), 'weights/netD_epoch_%d.pth' % (epoch))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/25][0/782] Loss_D: 0.3823 Loss_G: 2.4721 D(x): 0.7704 D(G(z)): 0.0715 / 0.1259\n",
            "[0/25][100/782] Loss_D: 0.5873 Loss_G: 2.4181 D(x): 0.6754 D(G(z)): 0.0270 / 0.1440\n",
            "[0/25][200/782] Loss_D: 0.4405 Loss_G: 3.0477 D(x): 0.7883 D(G(z)): 0.1376 / 0.0634\n",
            "[0/25][300/782] Loss_D: 0.1446 Loss_G: 3.8112 D(x): 0.9061 D(G(z)): 0.0320 / 0.0320\n",
            "[0/25][400/782] Loss_D: 0.3110 Loss_G: 3.8767 D(x): 0.8750 D(G(z)): 0.1321 / 0.0297\n",
            "[0/25][500/782] Loss_D: 0.4187 Loss_G: 4.5060 D(x): 0.8105 D(G(z)): 0.1352 / 0.0287\n",
            "[0/25][600/782] Loss_D: 0.5305 Loss_G: 4.6225 D(x): 0.9176 D(G(z)): 0.2768 / 0.0285\n",
            "[0/25][700/782] Loss_D: 0.7537 Loss_G: 1.7981 D(x): 0.6009 D(G(z)): 0.0756 / 0.2262\n",
            "[1/25][0/782] Loss_D: 0.6031 Loss_G: 3.7065 D(x): 0.9297 D(G(z)): 0.3488 / 0.0366\n",
            "[1/25][100/782] Loss_D: 0.6035 Loss_G: 2.4837 D(x): 0.6430 D(G(z)): 0.0563 / 0.1285\n",
            "[1/25][200/782] Loss_D: 0.2676 Loss_G: 3.5650 D(x): 0.8693 D(G(z)): 0.1055 / 0.0398\n",
            "[1/25][300/782] Loss_D: 2.1485 Loss_G: 7.9254 D(x): 0.9810 D(G(z)): 0.8271 / 0.0011\n",
            "[1/25][400/782] Loss_D: 0.9473 Loss_G: 1.6588 D(x): 0.4639 D(G(z)): 0.0439 / 0.2698\n",
            "[1/25][500/782] Loss_D: 0.4407 Loss_G: 2.9205 D(x): 0.8687 D(G(z)): 0.2340 / 0.0677\n",
            "[1/25][600/782] Loss_D: 0.5071 Loss_G: 3.6167 D(x): 0.8725 D(G(z)): 0.2533 / 0.0402\n",
            "[1/25][700/782] Loss_D: 0.3483 Loss_G: 3.6250 D(x): 0.8443 D(G(z)): 0.1399 / 0.0384\n",
            "[2/25][0/782] Loss_D: 1.0651 Loss_G: 0.7361 D(x): 0.4627 D(G(z)): 0.0576 / 0.5671\n",
            "[2/25][100/782] Loss_D: 0.5621 Loss_G: 3.6362 D(x): 0.8680 D(G(z)): 0.2984 / 0.0382\n",
            "[2/25][200/782] Loss_D: 0.3928 Loss_G: 3.4180 D(x): 0.8917 D(G(z)): 0.2212 / 0.0436\n",
            "[2/25][300/782] Loss_D: 0.6477 Loss_G: 1.8106 D(x): 0.6705 D(G(z)): 0.1630 / 0.2025\n",
            "[2/25][400/782] Loss_D: 0.7819 Loss_G: 3.5428 D(x): 0.9122 D(G(z)): 0.4529 / 0.0376\n",
            "[2/25][500/782] Loss_D: 1.5129 Loss_G: 1.2154 D(x): 0.2943 D(G(z)): 0.0380 / 0.3658\n",
            "[2/25][600/782] Loss_D: 0.6139 Loss_G: 2.2506 D(x): 0.6778 D(G(z)): 0.1538 / 0.1341\n",
            "[2/25][700/782] Loss_D: 0.4604 Loss_G: 3.2362 D(x): 0.9079 D(G(z)): 0.2821 / 0.0513\n",
            "[3/25][0/782] Loss_D: 0.7878 Loss_G: 1.2220 D(x): 0.5557 D(G(z)): 0.1192 / 0.3472\n",
            "[3/25][100/782] Loss_D: 0.9796 Loss_G: 3.4034 D(x): 0.7870 D(G(z)): 0.4394 / 0.0466\n",
            "[3/25][200/782] Loss_D: 0.6496 Loss_G: 1.8186 D(x): 0.6122 D(G(z)): 0.0885 / 0.2062\n",
            "[3/25][300/782] Loss_D: 1.1082 Loss_G: 3.8290 D(x): 0.9259 D(G(z)): 0.5713 / 0.0329\n",
            "[3/25][400/782] Loss_D: 0.9682 Loss_G: 3.4451 D(x): 0.7605 D(G(z)): 0.4195 / 0.0490\n",
            "[3/25][500/782] Loss_D: 2.9222 Loss_G: 4.7382 D(x): 0.9719 D(G(z)): 0.9152 / 0.0142\n",
            "[3/25][600/782] Loss_D: 3.4848 Loss_G: 0.0221 D(x): 0.0538 D(G(z)): 0.0052 / 0.9786\n",
            "[3/25][700/782] Loss_D: 0.4665 Loss_G: 3.9598 D(x): 0.8871 D(G(z)): 0.2650 / 0.0245\n",
            "[4/25][0/782] Loss_D: 1.7955 Loss_G: 4.6026 D(x): 0.9671 D(G(z)): 0.7749 / 0.0211\n",
            "[4/25][100/782] Loss_D: 0.1067 Loss_G: 4.6282 D(x): 0.9141 D(G(z)): 0.0133 / 0.0138\n",
            "[4/25][200/782] Loss_D: 0.4580 Loss_G: 4.1454 D(x): 0.9545 D(G(z)): 0.3034 / 0.0234\n",
            "[4/25][300/782] Loss_D: 0.8869 Loss_G: 3.6370 D(x): 0.8424 D(G(z)): 0.4487 / 0.0337\n",
            "[4/25][400/782] Loss_D: 0.3100 Loss_G: 3.9272 D(x): 0.9464 D(G(z)): 0.2060 / 0.0268\n",
            "[4/25][500/782] Loss_D: 1.0804 Loss_G: 2.2745 D(x): 0.6473 D(G(z)): 0.3773 / 0.1534\n",
            "[4/25][600/782] Loss_D: 1.1063 Loss_G: 6.1317 D(x): 0.9318 D(G(z)): 0.5729 / 0.0038\n",
            "[4/25][700/782] Loss_D: 0.4871 Loss_G: 1.7540 D(x): 0.6657 D(G(z)): 0.0407 / 0.2131\n",
            "[5/25][0/782] Loss_D: 0.1217 Loss_G: 3.7067 D(x): 0.9281 D(G(z)): 0.0435 / 0.0345\n",
            "[5/25][100/782] Loss_D: 0.7591 Loss_G: 2.0268 D(x): 0.8073 D(G(z)): 0.3539 / 0.1663\n",
            "[5/25][200/782] Loss_D: 0.1533 Loss_G: 4.2328 D(x): 0.9837 D(G(z)): 0.1234 / 0.0193\n",
            "[5/25][300/782] Loss_D: 0.2572 Loss_G: 4.2518 D(x): 0.9680 D(G(z)): 0.1922 / 0.0179\n",
            "[5/25][400/782] Loss_D: 0.1687 Loss_G: 3.5025 D(x): 0.9592 D(G(z)): 0.1154 / 0.0380\n",
            "[5/25][500/782] Loss_D: 0.1007 Loss_G: 4.2933 D(x): 0.9330 D(G(z)): 0.0279 / 0.0213\n",
            "[5/25][600/782] Loss_D: 0.6685 Loss_G: 3.0112 D(x): 0.7052 D(G(z)): 0.2060 / 0.0721\n",
            "[5/25][700/782] Loss_D: 0.4905 Loss_G: 1.7551 D(x): 0.7734 D(G(z)): 0.1685 / 0.2087\n",
            "[6/25][0/782] Loss_D: 0.3010 Loss_G: 3.5581 D(x): 0.7682 D(G(z)): 0.0167 / 0.0440\n",
            "[6/25][100/782] Loss_D: 1.6661 Loss_G: 4.0046 D(x): 0.8755 D(G(z)): 0.7116 / 0.0339\n",
            "[6/25][200/782] Loss_D: 0.9725 Loss_G: 5.7615 D(x): 0.9158 D(G(z)): 0.5320 / 0.0051\n",
            "[6/25][300/782] Loss_D: 0.2270 Loss_G: 2.9773 D(x): 0.8951 D(G(z)): 0.0987 / 0.0657\n",
            "[6/25][400/782] Loss_D: 0.6176 Loss_G: 2.6338 D(x): 0.5951 D(G(z)): 0.0351 / 0.0980\n",
            "[6/25][500/782] Loss_D: 1.0584 Loss_G: 1.7563 D(x): 0.4856 D(G(z)): 0.1752 / 0.2273\n",
            "[6/25][600/782] Loss_D: 0.7113 Loss_G: 1.8308 D(x): 0.6591 D(G(z)): 0.1917 / 0.1916\n",
            "[6/25][700/782] Loss_D: 0.1866 Loss_G: 3.5586 D(x): 0.9248 D(G(z)): 0.0984 / 0.0354\n",
            "[7/25][0/782] Loss_D: 0.4251 Loss_G: 3.6591 D(x): 0.9233 D(G(z)): 0.2653 / 0.0407\n",
            "[7/25][100/782] Loss_D: 0.5116 Loss_G: 3.0772 D(x): 0.8961 D(G(z)): 0.2905 / 0.0661\n",
            "[7/25][200/782] Loss_D: 0.0502 Loss_G: 4.6733 D(x): 0.9671 D(G(z)): 0.0161 / 0.0122\n",
            "[7/25][300/782] Loss_D: 0.3829 Loss_G: 2.2076 D(x): 0.7635 D(G(z)): 0.0667 / 0.1539\n",
            "[7/25][400/782] Loss_D: 0.1996 Loss_G: 3.8120 D(x): 0.9281 D(G(z)): 0.1089 / 0.0296\n",
            "[7/25][500/782] Loss_D: 0.5323 Loss_G: 1.8193 D(x): 0.7694 D(G(z)): 0.1982 / 0.2051\n",
            "[7/25][600/782] Loss_D: 3.7922 Loss_G: 7.8851 D(x): 0.9999 D(G(z)): 0.9606 / 0.0007\n",
            "[7/25][700/782] Loss_D: 0.0195 Loss_G: 4.6560 D(x): 0.9904 D(G(z)): 0.0098 / 0.0135\n",
            "[8/25][0/782] Loss_D: 0.6508 Loss_G: 3.4480 D(x): 0.8098 D(G(z)): 0.3203 / 0.0426\n",
            "[8/25][100/782] Loss_D: 0.0730 Loss_G: 4.3467 D(x): 0.9617 D(G(z)): 0.0321 / 0.0196\n",
            "[8/25][200/782] Loss_D: 0.8236 Loss_G: 2.5769 D(x): 0.6369 D(G(z)): 0.2351 / 0.1060\n",
            "[8/25][300/782] Loss_D: 0.7026 Loss_G: 0.2945 D(x): 0.6580 D(G(z)): 0.1577 / 0.7609\n",
            "[8/25][400/782] Loss_D: 2.8540 Loss_G: 0.1233 D(x): 0.0962 D(G(z)): 0.0184 / 0.8999\n",
            "[8/25][500/782] Loss_D: 0.1193 Loss_G: 4.3433 D(x): 0.9766 D(G(z)): 0.0880 / 0.0180\n",
            "[8/25][600/782] Loss_D: 0.2749 Loss_G: 5.3322 D(x): 0.9494 D(G(z)): 0.1799 / 0.0078\n",
            "[8/25][700/782] Loss_D: 0.5777 Loss_G: 2.4881 D(x): 0.6897 D(G(z)): 0.1350 / 0.1164\n",
            "[9/25][0/782] Loss_D: 0.5124 Loss_G: 4.9120 D(x): 0.9771 D(G(z)): 0.3496 / 0.0106\n",
            "[9/25][100/782] Loss_D: 0.0068 Loss_G: 6.5845 D(x): 0.9965 D(G(z)): 0.0032 / 0.0023\n",
            "[9/25][200/782] Loss_D: 0.0940 Loss_G: 4.4976 D(x): 0.9936 D(G(z)): 0.0801 / 0.0163\n",
            "[9/25][300/782] Loss_D: 0.0254 Loss_G: 6.0251 D(x): 0.9784 D(G(z)): 0.0033 / 0.0035\n",
            "[9/25][400/782] Loss_D: 0.6803 Loss_G: 2.2845 D(x): 0.6523 D(G(z)): 0.1457 / 0.1327\n",
            "[9/25][500/782] Loss_D: 0.3246 Loss_G: 3.3229 D(x): 0.9343 D(G(z)): 0.2023 / 0.0502\n",
            "[9/25][600/782] Loss_D: 0.2658 Loss_G: 2.7587 D(x): 0.8783 D(G(z)): 0.1143 / 0.0818\n",
            "[9/25][700/782] Loss_D: 0.3146 Loss_G: 2.5225 D(x): 0.8018 D(G(z)): 0.0637 / 0.1166\n",
            "[10/25][0/782] Loss_D: 0.0039 Loss_G: 5.6925 D(x): 0.9982 D(G(z)): 0.0021 / 0.0056\n",
            "[10/25][100/782] Loss_D: 2.2581 Loss_G: 2.6214 D(x): 0.9332 D(G(z)): 0.8369 / 0.0992\n",
            "[10/25][200/782] Loss_D: 1.1535 Loss_G: 1.1938 D(x): 0.3965 D(G(z)): 0.0789 / 0.3560\n",
            "[10/25][300/782] Loss_D: 0.6491 Loss_G: 1.9103 D(x): 0.8449 D(G(z)): 0.3352 / 0.1881\n",
            "[10/25][400/782] Loss_D: 0.0781 Loss_G: 3.8047 D(x): 0.9622 D(G(z)): 0.0370 / 0.0322\n",
            "[10/25][500/782] Loss_D: 0.8038 Loss_G: 2.1931 D(x): 0.5644 D(G(z)): 0.0845 / 0.1712\n",
            "[10/25][600/782] Loss_D: 0.1871 Loss_G: 4.7841 D(x): 0.8505 D(G(z)): 0.0057 / 0.0124\n",
            "[10/25][700/782] Loss_D: 0.6992 Loss_G: 2.3819 D(x): 0.7955 D(G(z)): 0.3342 / 0.1159\n",
            "[11/25][0/782] Loss_D: 0.0791 Loss_G: 3.6176 D(x): 0.9669 D(G(z)): 0.0430 / 0.0365\n",
            "[11/25][100/782] Loss_D: 0.2931 Loss_G: 3.6531 D(x): 0.9582 D(G(z)): 0.2064 / 0.0346\n",
            "[11/25][200/782] Loss_D: 0.1504 Loss_G: 4.0670 D(x): 0.9847 D(G(z)): 0.1212 / 0.0239\n",
            "[11/25][300/782] Loss_D: 0.5745 Loss_G: 2.7424 D(x): 0.6859 D(G(z)): 0.1164 / 0.0895\n",
            "[11/25][400/782] Loss_D: 0.8960 Loss_G: 2.9405 D(x): 0.8261 D(G(z)): 0.4675 / 0.0662\n",
            "[11/25][500/782] Loss_D: 0.1136 Loss_G: 3.5590 D(x): 0.9655 D(G(z)): 0.0732 / 0.0385\n",
            "[11/25][600/782] Loss_D: 0.9071 Loss_G: 1.1737 D(x): 0.4706 D(G(z)): 0.0562 / 0.3690\n",
            "[11/25][700/782] Loss_D: 0.0402 Loss_G: 4.8361 D(x): 0.9908 D(G(z)): 0.0292 / 0.0136\n",
            "[12/25][0/782] Loss_D: 0.5332 Loss_G: 2.7149 D(x): 0.6479 D(G(z)): 0.0385 / 0.1058\n",
            "[12/25][100/782] Loss_D: 0.5742 Loss_G: 5.5025 D(x): 0.9891 D(G(z)): 0.3963 / 0.0051\n",
            "[12/25][200/782] Loss_D: 0.6970 Loss_G: 3.2711 D(x): 0.7794 D(G(z)): 0.3229 / 0.0493\n",
            "[12/25][300/782] Loss_D: 0.0235 Loss_G: 4.8526 D(x): 0.9850 D(G(z)): 0.0082 / 0.0111\n",
            "[12/25][400/782] Loss_D: 0.8217 Loss_G: 3.1637 D(x): 0.7286 D(G(z)): 0.3354 / 0.0541\n",
            "[12/25][500/782] Loss_D: 0.6091 Loss_G: 2.7148 D(x): 0.7074 D(G(z)): 0.1772 / 0.0913\n",
            "[12/25][600/782] Loss_D: 0.9104 Loss_G: 5.8570 D(x): 0.9658 D(G(z)): 0.5133 / 0.0038\n",
            "[12/25][700/782] Loss_D: 0.2210 Loss_G: 4.4086 D(x): 0.9656 D(G(z)): 0.1582 / 0.0171\n",
            "[13/25][0/782] Loss_D: 0.2261 Loss_G: 2.9537 D(x): 0.8874 D(G(z)): 0.0937 / 0.0668\n",
            "[13/25][100/782] Loss_D: 0.0262 Loss_G: 5.2603 D(x): 0.9945 D(G(z)): 0.0202 / 0.0095\n",
            "[13/25][200/782] Loss_D: 6.3104 Loss_G: 4.4499 D(x): 0.0042 D(G(z)): 0.0003 / 0.0190\n",
            "[13/25][300/782] Loss_D: 3.2856 Loss_G: 1.5115 D(x): 0.0553 D(G(z)): 0.0081 / 0.3192\n",
            "[13/25][400/782] Loss_D: 0.2810 Loss_G: 3.2353 D(x): 0.8974 D(G(z)): 0.1412 / 0.0517\n",
            "[13/25][500/782] Loss_D: 0.1215 Loss_G: 3.8666 D(x): 0.9721 D(G(z)): 0.0853 / 0.0304\n",
            "[13/25][600/782] Loss_D: 0.0927 Loss_G: 6.0935 D(x): 0.9239 D(G(z)): 0.0034 / 0.0035\n",
            "[13/25][700/782] Loss_D: 0.5277 Loss_G: 2.7538 D(x): 0.7428 D(G(z)): 0.1606 / 0.0848\n",
            "[14/25][0/782] Loss_D: 0.9613 Loss_G: 4.9968 D(x): 0.9303 D(G(z)): 0.5343 / 0.0094\n",
            "[14/25][100/782] Loss_D: 0.7769 Loss_G: 1.6348 D(x): 0.5502 D(G(z)): 0.1075 / 0.2383\n",
            "[14/25][200/782] Loss_D: 0.0614 Loss_G: 4.2318 D(x): 0.9913 D(G(z)): 0.0504 / 0.0194\n",
            "[14/25][300/782] Loss_D: 0.0177 Loss_G: 5.5046 D(x): 0.9921 D(G(z)): 0.0096 / 0.0063\n",
            "[14/25][400/782] Loss_D: 0.3042 Loss_G: 3.5491 D(x): 0.9286 D(G(z)): 0.1895 / 0.0374\n",
            "[14/25][500/782] Loss_D: 0.6029 Loss_G: 3.4749 D(x): 0.8513 D(G(z)): 0.3101 / 0.0448\n",
            "[14/25][600/782] Loss_D: 0.6740 Loss_G: 3.1237 D(x): 0.8157 D(G(z)): 0.3170 / 0.0650\n",
            "[14/25][700/782] Loss_D: 0.3985 Loss_G: 5.3754 D(x): 0.9850 D(G(z)): 0.2909 / 0.0063\n",
            "[15/25][0/782] Loss_D: 0.0432 Loss_G: 4.2994 D(x): 0.9874 D(G(z)): 0.0292 / 0.0211\n",
            "[15/25][100/782] Loss_D: 0.6351 Loss_G: 2.4700 D(x): 0.6649 D(G(z)): 0.1403 / 0.1202\n",
            "[15/25][200/782] Loss_D: 0.5845 Loss_G: 1.1277 D(x): 0.6438 D(G(z)): 0.0698 / 0.3652\n",
            "[15/25][300/782] Loss_D: 0.4279 Loss_G: 3.0383 D(x): 0.8272 D(G(z)): 0.1867 / 0.0674\n",
            "[15/25][400/782] Loss_D: 0.0467 Loss_G: 4.1518 D(x): 0.9817 D(G(z)): 0.0272 / 0.0217\n",
            "[15/25][500/782] Loss_D: 0.1687 Loss_G: 3.6057 D(x): 0.8877 D(G(z)): 0.0432 / 0.0380\n",
            "[15/25][600/782] Loss_D: 0.0161 Loss_G: 8.3315 D(x): 0.9846 D(G(z)): 0.0004 / 0.0004\n",
            "[15/25][700/782] Loss_D: 0.4677 Loss_G: 3.6082 D(x): 0.8817 D(G(z)): 0.2513 / 0.0399\n",
            "[16/25][0/782] Loss_D: 0.6035 Loss_G: 1.7026 D(x): 0.7243 D(G(z)): 0.1757 / 0.2298\n",
            "[16/25][100/782] Loss_D: 0.4991 Loss_G: 2.4204 D(x): 0.7824 D(G(z)): 0.1881 / 0.1108\n",
            "[16/25][200/782] Loss_D: 0.8538 Loss_G: 2.0970 D(x): 0.7733 D(G(z)): 0.4010 / 0.1521\n",
            "[16/25][300/782] Loss_D: 1.7443 Loss_G: 2.5744 D(x): 0.2390 D(G(z)): 0.0065 / 0.1217\n",
            "[16/25][400/782] Loss_D: 0.5847 Loss_G: 2.0426 D(x): 0.6373 D(G(z)): 0.0636 / 0.1779\n",
            "[16/25][500/782] Loss_D: 0.0235 Loss_G: 5.4657 D(x): 0.9841 D(G(z)): 0.0072 / 0.0064\n",
            "[16/25][600/782] Loss_D: 0.6345 Loss_G: 1.6559 D(x): 0.6627 D(G(z)): 0.1574 / 0.2278\n",
            "[16/25][700/782] Loss_D: 0.0668 Loss_G: 4.6526 D(x): 0.9901 D(G(z)): 0.0534 / 0.0142\n",
            "[17/25][0/782] Loss_D: 0.3350 Loss_G: 2.3557 D(x): 0.8682 D(G(z)): 0.1579 / 0.1240\n",
            "[17/25][100/782] Loss_D: 0.6864 Loss_G: 1.9866 D(x): 0.8084 D(G(z)): 0.3395 / 0.1628\n",
            "[17/25][200/782] Loss_D: 0.0764 Loss_G: 4.6024 D(x): 0.9515 D(G(z)): 0.0200 / 0.0144\n",
            "[17/25][300/782] Loss_D: 0.5266 Loss_G: 2.6590 D(x): 0.8051 D(G(z)): 0.2277 / 0.0908\n",
            "[17/25][400/782] Loss_D: 0.7457 Loss_G: 2.3693 D(x): 0.8274 D(G(z)): 0.3803 / 0.1146\n",
            "[17/25][500/782] Loss_D: 0.2696 Loss_G: 3.9727 D(x): 0.9642 D(G(z)): 0.1962 / 0.0251\n",
            "[17/25][600/782] Loss_D: 0.0283 Loss_G: 4.7151 D(x): 0.9938 D(G(z)): 0.0216 / 0.0126\n",
            "[17/25][700/782] Loss_D: 0.8192 Loss_G: 3.2635 D(x): 0.8452 D(G(z)): 0.4288 / 0.0513\n",
            "[18/25][0/782] Loss_D: 0.2048 Loss_G: 5.9938 D(x): 0.8339 D(G(z)): 0.0064 / 0.0037\n",
            "[18/25][100/782] Loss_D: 0.1632 Loss_G: 3.4007 D(x): 0.9740 D(G(z)): 0.1216 / 0.0434\n",
            "[18/25][200/782] Loss_D: 0.4951 Loss_G: 2.1773 D(x): 0.8981 D(G(z)): 0.2886 / 0.1455\n",
            "[18/25][300/782] Loss_D: 0.8767 Loss_G: 1.4452 D(x): 0.5234 D(G(z)): 0.1375 / 0.2866\n",
            "[18/25][400/782] Loss_D: 0.0219 Loss_G: 5.7872 D(x): 0.9841 D(G(z)): 0.0055 / 0.0047\n",
            "[18/25][500/782] Loss_D: 0.5463 Loss_G: 2.3993 D(x): 0.8497 D(G(z)): 0.2753 / 0.1230\n",
            "[18/25][600/782] Loss_D: 1.0838 Loss_G: 4.0366 D(x): 0.6736 D(G(z)): 0.4166 / 0.0302\n",
            "[18/25][700/782] Loss_D: 0.6665 Loss_G: 1.8147 D(x): 0.6679 D(G(z)): 0.1797 / 0.2080\n",
            "[19/25][0/782] Loss_D: 0.3749 Loss_G: 3.9982 D(x): 0.8666 D(G(z)): 0.1773 / 0.0337\n",
            "[19/25][100/782] Loss_D: 0.9575 Loss_G: 5.2492 D(x): 0.9790 D(G(z)): 0.5500 / 0.0076\n",
            "[19/25][200/782] Loss_D: 0.0202 Loss_G: 5.3261 D(x): 0.9931 D(G(z)): 0.0130 / 0.0084\n",
            "[19/25][300/782] Loss_D: 0.0042 Loss_G: 6.2978 D(x): 0.9988 D(G(z)): 0.0030 / 0.0026\n",
            "[19/25][400/782] Loss_D: 0.1679 Loss_G: 3.6210 D(x): 0.9575 D(G(z)): 0.1111 / 0.0389\n",
            "[19/25][500/782] Loss_D: 0.9344 Loss_G: 5.4269 D(x): 0.9054 D(G(z)): 0.4992 / 0.0074\n",
            "[19/25][600/782] Loss_D: 1.6705 Loss_G: 0.9939 D(x): 0.2571 D(G(z)): 0.0079 / 0.4809\n",
            "[19/25][700/782] Loss_D: 0.3413 Loss_G: 2.6646 D(x): 0.8323 D(G(z)): 0.1198 / 0.0940\n",
            "[20/25][0/782] Loss_D: 1.7043 Loss_G: 5.2356 D(x): 0.2439 D(G(z)): 0.0019 / 0.0119\n",
            "[20/25][100/782] Loss_D: 0.5867 Loss_G: 4.2681 D(x): 0.9741 D(G(z)): 0.3852 / 0.0210\n",
            "[20/25][200/782] Loss_D: 0.5566 Loss_G: 3.1845 D(x): 0.8253 D(G(z)): 0.2668 / 0.0668\n",
            "[20/25][300/782] Loss_D: 0.1742 Loss_G: 2.6117 D(x): 0.9150 D(G(z)): 0.0751 / 0.1018\n",
            "[20/25][400/782] Loss_D: 0.4345 Loss_G: 2.8430 D(x): 0.8384 D(G(z)): 0.1980 / 0.0819\n",
            "[20/25][500/782] Loss_D: 0.1148 Loss_G: 5.2133 D(x): 0.9760 D(G(z)): 0.0681 / 0.0092\n",
            "[20/25][600/782] Loss_D: 0.4830 Loss_G: 2.9168 D(x): 0.8408 D(G(z)): 0.2414 / 0.0691\n",
            "[20/25][700/782] Loss_D: 0.5070 Loss_G: 2.6119 D(x): 0.7932 D(G(z)): 0.2063 / 0.0987\n",
            "[21/25][0/782] Loss_D: 0.5341 Loss_G: 5.1381 D(x): 0.9131 D(G(z)): 0.3095 / 0.0101\n",
            "[21/25][100/782] Loss_D: 0.8562 Loss_G: 7.4262 D(x): 0.9781 D(G(z)): 0.4910 / 0.0009\n",
            "[21/25][200/782] Loss_D: 0.7704 Loss_G: 2.6091 D(x): 0.8560 D(G(z)): 0.4026 / 0.0969\n",
            "[21/25][300/782] Loss_D: 0.0100 Loss_G: 6.1740 D(x): 0.9935 D(G(z)): 0.0034 / 0.0030\n",
            "[21/25][400/782] Loss_D: 0.0253 Loss_G: 5.4281 D(x): 0.9955 D(G(z)): 0.0203 / 0.0070\n",
            "[21/25][500/782] Loss_D: 0.1527 Loss_G: 4.0879 D(x): 0.9261 D(G(z)): 0.0692 / 0.0239\n",
            "[21/25][600/782] Loss_D: 0.0086 Loss_G: 6.1023 D(x): 0.9963 D(G(z)): 0.0048 / 0.0040\n",
            "[21/25][700/782] Loss_D: 0.0744 Loss_G: 4.3096 D(x): 0.9708 D(G(z)): 0.0417 / 0.0231\n",
            "[22/25][0/782] Loss_D: 0.6585 Loss_G: 3.6721 D(x): 0.8315 D(G(z)): 0.3390 / 0.0359\n",
            "[22/25][100/782] Loss_D: 0.4827 Loss_G: 3.2135 D(x): 0.7693 D(G(z)): 0.1491 / 0.0575\n",
            "[22/25][200/782] Loss_D: 0.0182 Loss_G: 7.1982 D(x): 0.9833 D(G(z)): 0.0011 / 0.0012\n",
            "[22/25][300/782] Loss_D: 0.5184 Loss_G: 1.8048 D(x): 0.6704 D(G(z)): 0.0631 / 0.2020\n",
            "[22/25][400/782] Loss_D: 0.7446 Loss_G: 1.3725 D(x): 0.6603 D(G(z)): 0.2082 / 0.3216\n",
            "[22/25][500/782] Loss_D: 0.9445 Loss_G: 3.9871 D(x): 0.7035 D(G(z)): 0.3573 / 0.0256\n",
            "[22/25][600/782] Loss_D: 0.0588 Loss_G: 3.7422 D(x): 0.9906 D(G(z)): 0.0470 / 0.0345\n",
            "[22/25][700/782] Loss_D: 0.6143 Loss_G: 1.5974 D(x): 0.6327 D(G(z)): 0.0946 / 0.2652\n",
            "[23/25][0/782] Loss_D: 0.4222 Loss_G: 4.0469 D(x): 0.9571 D(G(z)): 0.2818 / 0.0269\n",
            "[23/25][100/782] Loss_D: 0.2320 Loss_G: 3.3306 D(x): 0.9103 D(G(z)): 0.1131 / 0.0515\n",
            "[23/25][200/782] Loss_D: 0.0210 Loss_G: 5.2531 D(x): 0.9895 D(G(z)): 0.0102 / 0.0078\n",
            "[23/25][300/782] Loss_D: 0.0057 Loss_G: 7.6056 D(x): 0.9953 D(G(z)): 0.0009 / 0.0009\n",
            "[23/25][400/782] Loss_D: 0.2679 Loss_G: 3.7494 D(x): 0.9085 D(G(z)): 0.1425 / 0.0340\n",
            "[23/25][500/782] Loss_D: 0.8851 Loss_G: 3.0773 D(x): 0.7976 D(G(z)): 0.4154 / 0.0632\n",
            "[23/25][600/782] Loss_D: 0.3591 Loss_G: 3.2246 D(x): 0.8848 D(G(z)): 0.1857 / 0.0575\n",
            "[23/25][700/782] Loss_D: 0.5047 Loss_G: 3.5213 D(x): 0.6836 D(G(z)): 0.0570 / 0.0512\n",
            "[24/25][0/782] Loss_D: 0.4876 Loss_G: 1.9705 D(x): 0.7317 D(G(z)): 0.1265 / 0.1831\n",
            "[24/25][100/782] Loss_D: 0.4106 Loss_G: 2.4493 D(x): 0.8669 D(G(z)): 0.2035 / 0.1159\n",
            "[24/25][200/782] Loss_D: 0.7794 Loss_G: 2.6517 D(x): 0.7116 D(G(z)): 0.3026 / 0.0901\n",
            "[24/25][300/782] Loss_D: 0.4561 Loss_G: 2.3395 D(x): 0.8364 D(G(z)): 0.2092 / 0.1233\n",
            "[24/25][400/782] Loss_D: 0.1569 Loss_G: 7.0748 D(x): 0.8700 D(G(z)): 0.0004 / 0.0012\n",
            "[24/25][500/782] Loss_D: 0.4127 Loss_G: 2.2201 D(x): 0.7439 D(G(z)): 0.0659 / 0.1537\n",
            "[24/25][600/782] Loss_D: 0.1742 Loss_G: 3.8813 D(x): 0.9618 D(G(z)): 0.1162 / 0.0309\n",
            "[24/25][700/782] Loss_D: 0.0131 Loss_G: 6.7946 D(x): 0.9895 D(G(z)): 0.0025 / 0.0023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKDIOW6IaXXZ"
      },
      "source": [
        "# To copy results folder from Colab to G Drive folder\n",
        "\n",
        "!cp -r /content/results /content/drive/My\\ Drive/GANS/"
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}